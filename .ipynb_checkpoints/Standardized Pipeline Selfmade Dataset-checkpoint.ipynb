{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43caf0ad",
   "metadata": {},
   "source": [
    "# Standard Pipeline - Binary model Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ff57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block 1: Last inn datasett, fjern unødvendige kanaler, binær-annotasjon -----------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For reproducerbarhet\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1) Les inn alle CSV-filer\n",
    "csv_dir = './csv_output'\n",
    "csv_files = [os.path.join(csv_dir, f) for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
    "df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "\n",
    "# 2) Standardiser annotation-tekst\n",
    "df['annotation'] = df['annotation'].str.upper().str.strip()\n",
    "\n",
    "# 3) Identifiser EEG-kanaler: ta alle kolonner unntatt metadata, fjern AUX og DIR\n",
    "metadata_cols = ['Person', 'Recording', 'time', 'annotation']\n",
    "all_channels  = [c for c in df.columns if c not in metadata_cols]\n",
    "eeg_channels  = [c for c in all_channels if ('AUX' not in c.upper()) and ('DIR' not in c.upper())]\n",
    "\n",
    "# 4) Filtrer bort uønskede kolonner, behold kun EEG-signaler + metadata\n",
    "df = df[metadata_cols + eeg_channels].copy()\n",
    "\n",
    "# 5) Binær-annotasjon: behold kun REST eller IMAGERY-varianter, lag label\n",
    "df = df[df['annotation'].str.contains('REST|IMAGERY', na=False)].reset_index(drop=True)\n",
    "df['label'] = np.where(df['annotation'].str.contains('IMAGERY'), 'IMAGERY', 'REST')\n",
    "\n",
    "# 6) Sjekk datasett og klassedistribusjon\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"Antall EEG-kanaler:\", len(eeg_channels))\n",
    "print(\"Klassefordeling:\\n\", df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block 2: Notch- og båndpass-filtrering -----------------------------\n",
    "import mne\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Opprett MNE RawArray fra DataFrame\n",
    "sfreq = 500.0  # samplingfrekvens\n",
    "info = mne.create_info(ch_names=eeg_channels, sfreq=sfreq, ch_types='eeg')\n",
    "raw = mne.io.RawArray(df[eeg_channels].T.values, info)\n",
    "\n",
    "# 2) Notch-filter ved 50 Hz for å fjerne strømnettstøy\n",
    "#    - FIR-notching med smal båndbredde rundt 50 Hz\n",
    "raw.notch_filter(freqs=50., fir_design='firwin', verbose=True)\n",
    "\n",
    "# 3) Båndpass 1–40 Hz for å fange de viktigste EEG-båndene (drift ↔ gamma)\n",
    "#    - 1 Hz high-pass for å fjerne DC-drift\n",
    "#    - 40 Hz low-pass for å undertrykke høyfrekvent støy\n",
    "raw.filter(l_freq=1.0, h_freq=40.0, fir_design='firwin', verbose=True)\n",
    "\n",
    "# 4) Les det filtrerte signalet tilbake til en DataFrame\n",
    "df_filtered = pd.DataFrame(raw.get_data().T, columns=eeg_channels)\n",
    "\n",
    "# 5) Sjekk at filtreringen er brukt\n",
    "print(raw.info)                 # skal vise 32 EEG-kanaler @ 500 Hz\n",
    "print(\"First values (filtered):\")\n",
    "print(df_filtered.iloc[:5, :5])  # vis et lite utdrag av de filtrerte dataene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block 4 (oppdatert): Epoching med gruppelabels -----------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_clean = raw.get_data().T    \n",
    "persons    = df['Person'].values       \n",
    "recs       = df['Recording'].values    \n",
    "labels_all = df['label'].values        \n",
    "\n",
    "sfreq       = raw.info['sfreq']\n",
    "epoch_samps = int(4 * sfreq)\n",
    "step        = epoch_samps\n",
    "\n",
    "# 3) Lag epoker, majoritets-label og gruppelabel per epoke\n",
    "X_epochs, y_epochs, groups = [], [], []\n",
    "for start in range(0, len(data_clean) - epoch_samps + 1, step):\n",
    "    end = start + epoch_samps\n",
    "    seg = data_clean[start:end]    \n",
    "    baseline = seg[:int(0.5*sfreq), :].mean(axis=0, keepdims=True)\n",
    "    seg_bc = seg - baseline\n",
    "    X_epochs.append(seg_bc.T)\n",
    "    lab = pd.Series(labels_all[start:end]).mode()[0]\n",
    "    y_epochs.append(lab)\n",
    "    groups.append(f\"{persons[start]}__{recs[start]}\")\n",
    "\n",
    "X_epochs = np.array(X_epochs)    # (n_epochs, n_channels, n_times)\n",
    "y_epochs = np.array(y_epochs)\n",
    "groups    = np.array(groups)\n",
    "\n",
    "# 4) Sjekk\n",
    "import pandas as pd\n",
    "print(\"Epochs shape:\", X_epochs.shape)\n",
    "print(\"Label-fordeling:\\n\", pd.Series(y_epochs).value_counts())\n",
    "print(\"Antall unike grupper (Person__Recording):\", len(np.unique(groups)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75953558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block 5 (oppdatert): Group-based split i train/val/test -----------------------------\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Først: train vs (val+test)\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "train_idx, vt_idx = next(gss1.split(X_epochs, y_epochs, groups))\n",
    "\n",
    "# 2) Deretter: val vs test på det resterende\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=42)\n",
    "val_idx_rel, test_idx_rel = next(gss2.split(X_epochs[vt_idx], y_epochs[vt_idx], groups[vt_idx]))\n",
    "val_idx  = vt_idx[val_idx_rel]\n",
    "test_idx = vt_idx[test_idx_rel]\n",
    "\n",
    "# 3) Del opp data\n",
    "X_train, y_train = X_epochs[train_idx],    y_epochs[train_idx]\n",
    "X_val,   y_val   = X_epochs[val_idx],      y_epochs[val_idx]\n",
    "X_test,  y_test  = X_epochs[test_idx],     y_epochs[test_idx]\n",
    "\n",
    "# 4) Verifiser at ingen grupper overlapper\n",
    "train_groups = set(groups[train_idx])\n",
    "val_groups   = set(groups[val_idx])\n",
    "test_groups  = set(groups[test_idx])\n",
    "assert train_groups.isdisjoint(val_groups)\n",
    "assert train_groups.isdisjoint(test_groups)\n",
    "assert val_groups.isdisjoint(test_groups)\n",
    "print(\"Ingen gruppelekkasje mellom train/val/test ✔️\")\n",
    "\n",
    "# 5) Sjekk former og fordeling\n",
    "print(\"Train shape:\", X_train.shape, \" Val shape:\", X_val.shape, \" Test shape:\", X_test.shape)\n",
    "print(\"Train distrib:\\n\", pd.Series(y_train).value_counts())\n",
    "print(\"Val distrib:\\n\",   pd.Series(y_val).value_counts())\n",
    "print(\"Test distrib:\\n\",  pd.Series(y_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bfc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block 5 NEW – Balansér KUN treningssettet + evaluer -----------------------------\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.utils           import resample\n",
    "from pyriemann.estimation    import Covariances\n",
    "from pyriemann.tangentspace  import TangentSpace\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.metrics         import (\n",
    "    balanced_accuracy_score, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- 1) Oversampling av TRAIN ---------------------------------------\n",
    "df_tr = pd.DataFrame({'X': list(X_train), 'y': y_train})\n",
    "maj_sz = df_tr['y'].value_counts().max()         # størrelsen på majoritets­klassen\n",
    "\n",
    "rest_bal    = resample(df_tr[df_tr['y'] == 'REST'],\n",
    "                       replace=True, n_samples=maj_sz, random_state=42)\n",
    "imagery_bal = resample(df_tr[df_tr['y'] == 'IMAGERY'],\n",
    "                       replace=True, n_samples=maj_sz, random_state=42)\n",
    "\n",
    "df_tr_bal   = pd.concat([rest_bal, imagery_bal]).sample(frac=1, random_state=42)\n",
    "X_tr_bal    = np.stack(df_tr_bal['X'].values)\n",
    "y_tr_bal    = df_tr_bal['y'].values\n",
    "\n",
    "print(\"Etter oversampling (kun train):\")\n",
    "print(pd.Series(y_tr_bal).value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9957e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block 6–7 (OPPDATERT): Definer, tren og evaluer pipeline -----------------------------\n",
    "import numpy as np\n",
    "from pyriemann.estimation      import Covariances\n",
    "from pyriemann.tangentspace    import TangentSpace\n",
    "from sklearn.pipeline          import Pipeline\n",
    "from sklearn.preprocessing     import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.svm               import SVC\n",
    "from sklearn.metrics           import balanced_accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from model_utils import CovTransport\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cov',    Covariances(estimator='oas')),\n",
    "    ('align',  CovTransport()),\n",
    "    ('ts',     TangentSpace(metric='riemann')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('fs',     SelectKBest(mutual_info_classif, k=50)),\n",
    "    ('svm',    SVC(\n",
    "                   kernel='rbf',\n",
    "                   C=1.0,\n",
    "                   gamma='scale',\n",
    "                   class_weight=None,\n",
    "                   probability=True,    # <--- HER\n",
    "                   random_state=42))\n",
    "])\n",
    "\n",
    "# Tren på hele, balanserte datasettet\n",
    "pipe.fit(X_tr_bal, y_tr_bal)\n",
    "\n",
    "# 3) Evaluer på Val & Test\n",
    "for navn, Xf, yf in [('Val', X_val, y_val), ('Test', X_test, y_test)]:\n",
    "    yp      = pipe.predict(Xf)\n",
    "    bal_acc = balanced_accuracy_score(yf, yp)\n",
    "    print(f\"\\n{navn} balanced accuracy: {bal_acc:.3f}\")\n",
    "    print(classification_report(yf, yp, target_names=['REST','IMAGERY']))\n",
    "    print(f\"{navn} confusion matrix:\\n\", confusion_matrix(yf, yp, labels=['REST','IMAGERY']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180eb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block 8 (fiks): Plot Confusion Matrix for Test-set -----------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 0) Hvis du bruker end-to-end‐pipeline:\n",
    "#    y_test_pred = pipe.predict(X_test)\n",
    "# Eller hvis du bruker forhånds-ekstraherte features:\n",
    "#    y_test_pred = pipe.predict(X_test_feat)\n",
    "y_test_pred = pipe.predict(X_test)  \n",
    "\n",
    "labels = ['REST', 'IMAGERY']\n",
    "\n",
    "# 1) Skriv ut klassifikasjonsrapport med riktig etikett‐rekkefølge\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_test_pred,\n",
    "    labels=labels,\n",
    "    target_names=labels,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# 2) Beregn og plott forvirringsmatrisen med samme etiketter\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel('Predicted label')\n",
    "ax.set_ylabel('True label')\n",
    "ax.set_title('Confusion Matrix (Test Set)')\n",
    "\n",
    "# Annoter hver rute med tall\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, cm[i, j],\n",
    "                ha='center', va='center',\n",
    "                color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e60279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53b544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc688bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab112e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81239beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80719118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f053eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd4705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67f14c51",
   "metadata": {},
   "source": [
    "### Testing Binary Model - Remember to delete Person5 csv file before running pipeline first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block 5 (for deploy): 1–1 balansert oversampling -----------------------------\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Kombiner alle epoker til én DataFrame\n",
    "df_full    = pd.DataFrame({'X': list(X_epochs), 'y': y_epochs})\n",
    "\n",
    "# 2) Skill på REST vs IMAGERY\n",
    "rest_df    = df_full[df_full['y'] == 'REST']\n",
    "imagery_df = df_full[df_full['y'] == 'IMAGERY']\n",
    "\n",
    "# 3) Finn størrelsen på den største klassen\n",
    "n_max = max(len(rest_df), len(imagery_df))\n",
    "\n",
    "# 4) Oversample begge klasser til n_max\n",
    "rest_bal    = resample(rest_df,    replace=True, n_samples=n_max, random_state=42)\n",
    "imagery_bal = resample(imagery_df, replace=True, n_samples=n_max, random_state=42)\n",
    "\n",
    "# 5) Slå sammen, shuffle, og hent arrays\n",
    "df_bal      = pd.concat([rest_bal, imagery_bal]).sample(frac=1, random_state=42)\n",
    "X_full_bal  = np.stack(df_bal['X'].values)  # shape (2 * n_max, n_ch, n_times)\n",
    "y_full_bal  = df_bal['y'].values\n",
    "\n",
    "# 6) Sjekk at det er 50/50\n",
    "print(\"Etter 1:1 balansering:\")\n",
    "print(pd.Series(y_full_bal).value_counts())\n",
    "\n",
    "# 7) Tren modellen på hele, nå balanserte datasettet\n",
    "pipe.fit(X_full_bal, y_full_bal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block A: Convert Person5 Recording4 to CSV -----------------------------\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "\n",
    "mne.set_log_level('ERROR')\n",
    "root       = './data/selfmade_dataset/Person5/Recording4'\n",
    "output_dir = './csv_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "vhdr     = next(f for f in os.listdir(root) if f.endswith('.vhdr'))\n",
    "basename = vhdr[:-5]\n",
    "vhdr_path = os.path.join(root, vhdr)\n",
    "\n",
    "# Fix DataFile/MarkerFile\n",
    "lines = open(vhdr_path, 'r', encoding='utf-8').read().splitlines()\n",
    "with open(vhdr_path, 'w', encoding='utf-8') as f:\n",
    "    for L in lines:\n",
    "        if L.startswith('DataFile='):\n",
    "            f.write(f'DataFile={basename}.eeg\\n')\n",
    "        elif L.startswith('MarkerFile='):\n",
    "            f.write(f'MarkerFile={basename}.vmrk\\n')\n",
    "        else:\n",
    "            f.write(L + '\\n')\n",
    "\n",
    "# Read raw, to DataFrame, save CSV\n",
    "raw = mne.io.read_raw_brainvision(vhdr_path, preload=True,\n",
    "                                  eog=[], misc=['Aux1','Aux2','x_dir','y_dir','z_dir'])\n",
    "df  = raw.to_data_frame()  # inkl. 'time'\n",
    "df['annotation'] = ''\n",
    "for onset,dur,desc in zip(raw.annotations.onset,\n",
    "                          raw.annotations.duration,\n",
    "                          raw.annotations.description):\n",
    "    mask = (df['time'] >= onset) & (df['time'] < onset + dur)\n",
    "    df.loc[mask, 'annotation'] = desc\n",
    "\n",
    "out_csv = os.path.join(output_dir, f'{basename}.csv')\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"Saved CSV: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block B: Clean & extend annotations, add Person/Recording -----------------------------\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_file = './csv_output/Person5Recording4.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Forward-fill annotations, strip prefixes\n",
    "df['annotation'] = df['annotation'].replace('', np.nan)\n",
    "df['annotation'] = df['annotation'].str.replace(r'^Stimulus/', '', regex=True)\n",
    "df['annotation'] = df['annotation'].ffill().fillna('')\n",
    "\n",
    "# Fjern uønsket\n",
    "for unwanted in ['New Segment/', 'START', 'END']:\n",
    "    df = df[df['annotation'] != unwanted]\n",
    "df['annotation'] = df['annotation'].replace('New Segment/LostSamples: 1', 'REST')\n",
    "\n",
    "# Legg på Person/Recording\n",
    "m = re.match(r'Person(\\d+)Recording(\\d+)', 'Person5Recording4')\n",
    "person, rec = m.groups()\n",
    "df.insert(0, 'Recording', int(rec))\n",
    "df.insert(0, 'Person',    int(person))\n",
    "\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"Cleaned annotations, saved: {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccfa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block C: Preprocess & epoch new data -----------------------------\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load\n",
    "df_new = pd.read_csv(csv_file)\n",
    "\n",
    "# Hold kun REST/IMAGERY og lag label\n",
    "df_new['annotation'] = df_new['annotation'].str.upper().str.strip()\n",
    "df_new = df_new[df_new['annotation'].str.contains('REST|IMAGERY', na=False)].reset_index(drop=True)\n",
    "df_new['label']  = np.where(df_new['annotation'].str.contains('IMAGERY'), 'IMAGERY', 'REST')\n",
    "\n",
    "# EEG-kanaler hardkodet som i trening\n",
    "eeg_ch = [\n",
    "    'Fp1','Fz','F3','F7','FT9','FC5','FC1','C3','T7','TP9','CP5','CP1',\n",
    "    'Pz','P3','P7','O1','Oz','O2','P4','P8','TP10','CP6','CP2','Cz',\n",
    "    'C4','T8','FT10','FC6','FC2','F4','F8','Fp2'\n",
    "]\n",
    "\n",
    "# Drop non-numeric\n",
    "for ch in eeg_ch:\n",
    "    df_new[ch] = pd.to_numeric(df_new[ch], errors='coerce')\n",
    "df_new.dropna(subset=eeg_ch, inplace=True)\n",
    "df_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# RawArray + filter\n",
    "sfreq = 500.0\n",
    "info  = mne.create_info(ch_names=eeg_ch, sfreq=sfreq, ch_types='eeg')\n",
    "raw_new = mne.io.RawArray(df_new[eeg_ch].T.values, info)\n",
    "raw_new.notch_filter(50.,  fir_design='firwin', verbose=False)\n",
    "raw_new.filter(1., 40.,  fir_design='firwin', verbose=False)\n",
    "\n",
    "# Epoch 4 s non-overlap + baseline\n",
    "data        = raw_new.get_data().T\n",
    "labels      = df_new['label'].values\n",
    "epoch_samps = int(4 * sfreq)\n",
    "\n",
    "X_new, y_new = [], []\n",
    "for st in range(0, len(data) - epoch_samps + 1, epoch_samps):\n",
    "    seg      = data[st:st+epoch_samps]\n",
    "    baseline = seg[:int(0.5*sfreq)].mean(0, keepdims=True)\n",
    "    seg_bc   = seg - baseline\n",
    "    X_new.append(seg_bc.T)\n",
    "    y_new.append(pd.Series(labels[st:st+epoch_samps]).mode()[0])\n",
    "\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)\n",
    "print(\"New epochs:\", X_new.shape)\n",
    "print(\"New label counts:\\n\", pd.Series(y_new).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Block D: Evaluate on unseen Person5 -----------------------------\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Predikér med pipen\n",
    "y_new_pred = pipe.predict(X_new)\n",
    "\n",
    "# 2) Metrics\n",
    "acc_new = accuracy_score(y_new, y_new_pred)\n",
    "print(f\"\\nHoldout Person5 accuracy: {acc_new:.3f}\\n\")\n",
    "print(classification_report(\n",
    "    y_new, y_new_pred,\n",
    "    labels=['REST','IMAGERY'],\n",
    "    target_names=['REST','IMAGERY'],\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# 3) Plot konfusjonsmatrise\n",
    "cm = confusion_matrix(y_new, y_new_pred, labels=['REST','IMAGERY'])\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, cm[i,j],\n",
    "                ha='center', va='center',\n",
    "                color='white' if cm[i,j] > thresh else 'black')\n",
    "ax.set_xticks([0,1]); ax.set_xticklabels(['REST','IMAGERY'])\n",
    "ax.set_yticks([0,1]); ax.set_yticklabels(['REST','IMAGERY'])\n",
    "ax.set_xlabel('Predikert'); ax.set_ylabel('Sann')\n",
    "ax.set_title('Confusion Matrix: Person5 Recording4')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb09f27",
   "metadata": {},
   "source": [
    "## Deploy Standard Pipeline - Binary model Selfmade - Rerun everything with Person5 included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e268c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "ART_DIR = './saved_artifacts'\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "# 1) Lagre den oppdaterte pipeline (med probability=True)\n",
    "dump(pipe, os.path.join(ART_DIR, 'lda_riemann_pipeline.joblib'))\n",
    "\n",
    "# 2) Lagre kanallisten\n",
    "with open(os.path.join(ART_DIR, 'eeg_channels.json'), 'w') as f:\n",
    "    json.dump(eeg_channels, f)\n",
    "\n",
    "# 3) Lagre preproc‐parametre (vindustørrelse + step)\n",
    "meta = {\n",
    "    \"sfreq\":     int(sfreq),            # 500\n",
    "    \"window_len\": int(4 * sfreq),       # 2000 prøver\n",
    "    \"step_len\":   int(4 * sfreq)        # 1000 prøver\n",
    "}\n",
    "with open(os.path.join(ART_DIR, 'preproc_meta.json'), 'w') as f:\n",
    "    json.dump(meta, f)\n",
    "\n",
    "# 4) Lagre klasser (i riktig rekkefølge)\n",
    "np.save(os.path.join(ART_DIR, 'label_classes.npy'), pipe.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35915fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814e287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf0d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ca725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d29f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71ac82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d2f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238790b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3177e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2165f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb0cb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db672128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cb0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4e0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c3d8d9",
   "metadata": {},
   "source": [
    "# Standard Pipeline - Multiclass model Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad7bc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (2856759, 37)\n",
      "Antall EEG‐kanaler: 32\n",
      "Klassefordeling:\n",
      " REST       1429770\n",
      "MOVE        765950\n",
      "IMAGERY     661039\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------- Block 1: Last inn datasett, fjern unødvendige kanaler, tre‐klasses annotasjon -----------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For reproducerbarhet\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1) Les inn alle CSV-filer\n",
    "csv_dir   = './csv_output'\n",
    "csv_files = [os.path.join(csv_dir, f) for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
    "df        = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "\n",
    "# 2) Standardiser annotation‐tekst\n",
    "df['annotation'] = df['annotation'].str.upper().str.strip()\n",
    "\n",
    "# 3) Identifiser EEG‐kanaler\n",
    "metadata_cols = ['Person','Recording','time','annotation']\n",
    "all_ch        = [c for c in df.columns if c not in metadata_cols]\n",
    "eeg_channels  = [c for c in all_ch if ('AUX' not in c.upper()) and ('DIR' not in c.upper())]\n",
    "\n",
    "# 4) Behold kun EEG‐signal + metadata\n",
    "df = df[metadata_cols + eeg_channels].copy()\n",
    "\n",
    "# 5) Tre‐klasses annotasjon: REST, MOVE eller IMAGERY\n",
    "keep = df['annotation'].str.contains('REST|MOVE|IMAGERY', na=False)\n",
    "df   = df[keep].reset_index(drop=True)\n",
    "def map_label(text):\n",
    "    if 'MOVE'    in text: return 'MOVE'\n",
    "    if 'IMAGERY' in text: return 'IMAGERY'\n",
    "    return 'REST'\n",
    "df['label'] = df['annotation'].apply(map_label)\n",
    "\n",
    "# 6) Sjekk\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"Antall EEG‐kanaler:\", len(eeg_channels))\n",
    "print(\"Klassefordeling:\\n\", df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ef95f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=32, n_times=2856759\n",
      "    Range : 0 ... 2856758 =      0.000 ...  5713.516 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 3301 samples (6.602 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, TP9, CP5, CP1, Pz, P3, ...\n",
      " chs: 32 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 1.0 Hz\n",
      " lowpass: 40.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 32\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      ">\n",
      "First filtered values:\n",
      "             Fp1            Fz            F3            F7           FT9\n",
      "0 -1.944755e-11 -7.560175e-12 -7.034373e-13 -6.039613e-12  2.091838e-11\n",
      "1 -2.200908e+01  1.963600e+01  3.155345e+00 -4.357986e+00 -1.367513e+01\n",
      "2 -3.754336e+01  3.940387e+01  9.854597e+00 -5.567626e+00 -2.193492e+01\n",
      "3 -4.195389e+01  5.896188e+01  2.258597e+01 -1.556448e+00 -2.099057e+01\n",
      "4 -3.372132e+01  7.722065e+01  4.200556e+01  7.879740e+00 -9.819143e+00\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "\n",
    "# 1) Opprett MNE RawArray fra DataFrame\n",
    "sfreq = 500.0  # samplingfrekvens\n",
    "info  = mne.create_info(ch_names=eeg_channels, sfreq=sfreq, ch_types='eeg')\n",
    "raw   = mne.io.RawArray(df[eeg_channels].T.values, info)\n",
    "\n",
    "# 2) Notch-filter ved 50 Hz\n",
    "raw.notch_filter(freqs=50., fir_design='firwin', verbose=True)\n",
    "\n",
    "# 3) Båndpass 1–40 Hz\n",
    "raw.filter(l_freq=1.0, h_freq=40.0, fir_design='firwin', verbose=True)\n",
    "\n",
    "# 4) Les filtrert signal tilbake til DataFrame\n",
    "df_filtered = pd.DataFrame(raw.get_data().T, columns=eeg_channels)\n",
    "\n",
    "# 5) Sjekk\n",
    "print(raw.info)\n",
    "print(\"First filtered values:\\n\", df_filtered.iloc[:5, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a915d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs shape: (1428, 32, 2000)\n",
      "Label-fordeling:\n",
      " REST       710\n",
      "MOVE       384\n",
      "IMAGERY    334\n",
      "dtype: int64\n",
      "Antall unike grupper (Person__Recording): 16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_clean  = raw.get_data().T\n",
    "persons     = df['Person'].values\n",
    "recs        = df['Recording'].values\n",
    "labels_all  = df['label'].values\n",
    "\n",
    "sfreq       = raw.info['sfreq']\n",
    "epoch_samps = int(4 * sfreq)\n",
    "step        = epoch_samps\n",
    "\n",
    "X_epochs, y_epochs, groups = [], [], []\n",
    "for start in range(0, len(data_clean) - epoch_samps + 1, step):\n",
    "    seg      = data_clean[start:start+epoch_samps]\n",
    "    baseline = seg[:int(0.5*sfreq), :].mean(axis=0, keepdims=True)\n",
    "    seg_bc   = seg - baseline\n",
    "    X_epochs.append(seg_bc.T)\n",
    "    y_epochs.append(pd.Series(labels_all[start:start+epoch_samps]).mode()[0])\n",
    "    groups.append(f\"{persons[start]}__{recs[start]}\")\n",
    "\n",
    "X_epochs = np.array(X_epochs)\n",
    "y_epochs = np.array(y_epochs)\n",
    "groups    = np.array(groups)\n",
    "\n",
    "print(\"Epochs shape:\", X_epochs.shape)\n",
    "print(\"Label-fordeling:\\n\", pd.Series(y_epochs).value_counts())\n",
    "print(\"Antall unike grupper (Person__Recording):\", len(np.unique(groups)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548041eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingen gruppelekkasje ✔️\n",
      "Train: (1069, 32, 2000) REST       530\n",
      "MOVE       291\n",
      "IMAGERY    248\n",
      "dtype: int64\n",
      "Val:   (144, 32, 2000) REST       76\n",
      "MOVE       36\n",
      "IMAGERY    32\n",
      "dtype: int64\n",
      "Test:  (215, 32, 2000) REST       104\n",
      "MOVE        57\n",
      "IMAGERY     54\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Train vs (val+test)\n",
    "gss1    = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "train_idx, vt_idx = next(gss1.split(X_epochs, y_epochs, groups))\n",
    "\n",
    "# 2) Val vs Test på det resterende\n",
    "gss2    = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=42)\n",
    "val_rel, test_rel = next(gss2.split(X_epochs[vt_idx], y_epochs[vt_idx], groups[vt_idx]))\n",
    "val_idx, test_idx = vt_idx[val_rel], vt_idx[test_rel]\n",
    "\n",
    "# 3) Del opp\n",
    "X_train, y_train = X_epochs[train_idx], y_epochs[train_idx]\n",
    "X_val,   y_val   = X_epochs[val_idx],   y_epochs[val_idx]\n",
    "X_test,  y_test  = X_epochs[test_idx],  y_epochs[test_idx]\n",
    "\n",
    "# 4) Sjekk gruppelekkasje\n",
    "assert set(groups[train_idx]).isdisjoint(groups[val_idx])\n",
    "assert set(groups[train_idx]).isdisjoint(groups[test_idx])\n",
    "assert set(groups[val_idx]).isdisjoint(groups[test_idx])\n",
    "print(\"Ingen gruppelekkasje ✔️\")\n",
    "\n",
    "# 5) Form og fordeling\n",
    "print(\"Train:\", X_train.shape, pd.Series(y_train).value_counts())\n",
    "print(\"Val:  \", X_val.shape,   pd.Series(y_val).value_counts())\n",
    "print(\"Test: \", X_test.shape,  pd.Series(y_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939a41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train etter 1:1:1-oversampling:\n",
      " IMAGERY    530\n",
      "REST       530\n",
      "MOVE       530\n",
      "dtype: int64\n",
      "Val (uendret):\n",
      " REST       76\n",
      "MOVE       36\n",
      "IMAGERY    32\n",
      "dtype: int64\n",
      "Test (uendret):\n",
      " REST       104\n",
      "MOVE        57\n",
      "IMAGERY     54\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Block: 1:1:1 balansert oversampling kun på train ------------------\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Lag DataFrame KUN av treningssettet\n",
    "df_train = pd.DataFrame({'X': list(X_train), 'y': y_train})\n",
    "\n",
    "# 2) Del opp etter klasse\n",
    "dfs = {lab: df_train[df_train['y'] == lab]\n",
    "       for lab in ['REST', 'MOVE', 'IMAGERY']}\n",
    "\n",
    "# 3) Finn størrelsen på den største klassen i train\n",
    "n_max = max(len(dfs['REST']), len(dfs['MOVE']), len(dfs['IMAGERY']))\n",
    "\n",
    "# 4) Oversample hver klasse til n_max\n",
    "balanced = [\n",
    "    resample(dfs[lab], replace=True, n_samples=n_max, random_state=42)\n",
    "    for lab in dfs\n",
    "]\n",
    "df_train_bal = pd.concat(balanced).sample(frac=1, random_state=42)\n",
    "\n",
    "# 5) Pakk ut balansert treningssett\n",
    "X_train_bal = np.stack(df_train_bal['X'].values)\n",
    "y_train_bal = df_train_bal['y'].values\n",
    "\n",
    "# 6) Sjekk at kun train er 1:1:1\n",
    "print(\"Train etter 1:1:1-oversampling:\\n\", pd.Series(y_train_bal).value_counts())\n",
    "print(\"Val (uendret):\\n\", pd.Series(y_val).value_counts())\n",
    "print(\"Test (uendret):\\n\", pd.Series(y_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687f4019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val balanced accuracy: 0.536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        REST       0.67      0.59      0.63        76\n",
      "        MOVE       0.44      0.11      0.18        36\n",
      "     IMAGERY       0.43      0.91      0.58        32\n",
      "\n",
      "    accuracy                           0.54       144\n",
      "   macro avg       0.51      0.54      0.46       144\n",
      "weighted avg       0.56      0.54      0.51       144\n",
      "\n",
      "Val confusion matrix:\n",
      " [[45  5 26]\n",
      " [19  4 13]\n",
      " [ 3  0 29]]\n",
      "\n",
      "Test balanced accuracy: 0.493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        REST       0.59      0.69      0.63       104\n",
      "        MOVE       0.50      0.19      0.28        57\n",
      "     IMAGERY       0.46      0.59      0.52        54\n",
      "\n",
      "    accuracy                           0.53       215\n",
      "   macro avg       0.51      0.49      0.48       215\n",
      "weighted avg       0.53      0.53      0.51       215\n",
      "\n",
      "Test confusion matrix:\n",
      " [[72 10 22]\n",
      " [30 11 16]\n",
      " [21  1 32]]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------- Block X: Multiklasse‐pipeline med CSP, Riemann + SVM -----------------------------\n",
    "import numpy as np\n",
    "from pyriemann.estimation      import Covariances\n",
    "from pyriemann.spatialfilters  import CSP\n",
    "from pyriemann.tangentspace    import TangentSpace\n",
    "from sklearn.pipeline          import Pipeline\n",
    "from sklearn.preprocessing     import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.svm               import SVC\n",
    "\n",
    "from model_utils import CovTransport\n",
    "\n",
    "# Gi MOVE‐klassen litt ekstra vekt\n",
    "class_weights = {'REST': 1, 'MOVE': 1, 'IMAGERY': 1}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    # 1) Estimer SPD‐kovarianser\n",
    "    ('cov',    Covariances(estimator='oas')),\n",
    "\n",
    "    # 2) CSP på kovarianser: hent ut 6 komponenter totalt\n",
    "    ('csp',    CSP(nfilter=6, log=False)),        \n",
    "\n",
    "    # 3) Fjern person‐bias i tangentrommet\n",
    "    ('align',  CovTransport()),                     \n",
    "\n",
    "    # 4) Prosjekter til tangentrom\n",
    "    ('ts',     TangentSpace(metric='riemann')),      \n",
    "\n",
    "    # 5) Standardiser + behold alle features (k='all')\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('fs',     SelectKBest(mutual_info_classif, k='all')),  \n",
    "\n",
    "    # 6) SVM med vektet MOVE‐klasse og sannsynligheter\n",
    "    ('svm',    SVC(\n",
    "                   kernel='rbf',\n",
    "                   C=1.0,\n",
    "                   gamma='scale',\n",
    "                   class_weight=class_weights,\n",
    "                   probability=True,\n",
    "                   random_state=42))\n",
    "])\n",
    "\n",
    "# Tren på 1:1:1‐balanserte data\n",
    "pipe.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Evaluer på Val & Test\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "for navn, Xf, yf in [('Val', X_val, y_val), ('Test', X_test, y_test)]:\n",
    "    yp      = pipe.predict(Xf)\n",
    "    bal_acc = balanced_accuracy_score(yf, yp)\n",
    "    print(f\"\\n{navn} balanced accuracy: {bal_acc:.3f}\")\n",
    "    print(classification_report(\n",
    "        yf, yp,\n",
    "        labels=['REST','MOVE','IMAGERY'],\n",
    "        target_names=['REST','MOVE','IMAGERY']\n",
    "    ))\n",
    "    print(f\"{navn} confusion matrix:\\n\",\n",
    "          confusion_matrix(yf, yp, labels=['REST','MOVE','IMAGERY']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a70395ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        REST       0.59      0.69      0.63       104\n",
      "        MOVE       0.50      0.19      0.28        57\n",
      "     IMAGERY       0.46      0.59      0.52        54\n",
      "\n",
      "    accuracy                           0.53       215\n",
      "   macro avg       0.51      0.49      0.48       215\n",
      "weighted avg       0.53      0.53      0.51       215\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "labels      = ['REST','MOVE','IMAGERY']\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, y_test_pred,\n",
    "    labels=labels,\n",
    "    target_names=labels,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=labels)\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax.set_xticks(range(3)); ax.set_xticklabels(labels)\n",
    "ax.set_yticks(range(3)); ax.set_yticklabels(labels)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax.text(j, i, cm[i,j], ha='center', va='center',\n",
    "                color='white' if cm[i,j] > cm.max()/2 else 'black')\n",
    "plt.xlabel('Predikert'); plt.ylabel('Sann'); plt.title('Confusion Matrix (Test)')\n",
    "plt.colorbar(im); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c73dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b1d923",
   "metadata": {},
   "source": [
    "## Testing Standard Pipeline - Multiclass model Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Balanse and use the whole dataset. Train on train, val and test\n",
    "\n",
    "# ----------------------------- Block: 1:1:1 balansert oversampling -----------------------------\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Lag DataFrame av alle epoker\n",
    "df_full = pd.DataFrame({'X': list(X_epochs), 'y': y_epochs})\n",
    "\n",
    "# 2) Del opp etter klasse\n",
    "dfs = {lab: df_full[df_full['y']==lab] for lab in ['REST','MOVE','IMAGERY']}\n",
    "\n",
    "# 3) Finn størrelsen på den største klassen\n",
    "n_max = max(len(dfs['REST']), len(dfs['MOVE']), len(dfs['IMAGERY']))\n",
    "\n",
    "# 4) Oversample alle klasser til n_max\n",
    "balanced = [\n",
    "    resample(dfs[lab], replace=True, n_samples=n_max, random_state=42)\n",
    "    for lab in dfs\n",
    "]\n",
    "df_bal     = pd.concat(balanced).sample(frac=1, random_state=42)\n",
    "X_full_bal = np.stack(df_bal['X'].values)   # shape (3 * n_max, n_ch, n_times)\n",
    "y_full_bal = df_bal['y'].values\n",
    "\n",
    "print(\"Etter 1:1:1 balansering:\\n\", pd.Series(y_full_bal).value_counts())\n",
    "\n",
    "# 7) Tren modellen på hele, nå balanserte datasettet\n",
    "pipe.fit(X_full_bal, y_full_bal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "\n",
    "mne.set_log_level('ERROR')\n",
    "root       = './data/selfmade_dataset/Person5/Recording4'\n",
    "output_dir = './csv_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "vhdr     = next(f for f in os.listdir(root) if f.endswith('.vhdr'))\n",
    "basename = vhdr[:-5]\n",
    "vhdr_path = os.path.join(root, vhdr)\n",
    "\n",
    "# Fix paths\n",
    "lines = open(vhdr_path, 'r').read().splitlines()\n",
    "with open(vhdr_path, 'w') as f:\n",
    "    for L in lines:\n",
    "        if L.startswith('DataFile='):   f.write(f'DataFile={basename}.eeg\\n')\n",
    "        elif L.startswith('MarkerFile='): f.write(f'MarkerFile={basename}.vmrk\\n')\n",
    "        else:                            f.write(L + '\\n')\n",
    "\n",
    "# Read raw → DataFrame → CSV\n",
    "raw = mne.io.read_raw_brainvision(vhdr_path, preload=True,\n",
    "                                  eog=[], misc=['Aux1','Aux2','x_dir','y_dir','z_dir'])\n",
    "df  = raw.to_data_frame()\n",
    "df['annotation'] = ''\n",
    "for o,d,desc in zip(raw.annotations.onset,\n",
    "                    raw.annotations.duration,\n",
    "                    raw.annotations.description):\n",
    "    mask = (df['time']>=o)&(df['time']<o+d)\n",
    "    df.loc[mask,'annotation'] = desc\n",
    "\n",
    "out_csv = os.path.join(output_dir, f'{basename}.csv')\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"Saved CSV: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ad2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_file = './csv_output/Person5Recording4.csv'\n",
    "df       = pd.read_csv(csv_file)\n",
    "\n",
    "df['annotation'] = df['annotation'].replace('', np.nan)\n",
    "df['annotation'] = df['annotation'].str.replace(r'^Stimulus/', '', regex=True)\n",
    "df['annotation'] = df['annotation'].ffill().fillna('')\n",
    "\n",
    "for unwanted in ['New Segment/','START','END']:\n",
    "    df = df[df['annotation']!=unwanted]\n",
    "df['annotation'] = df['annotation'].replace('New Segment/LostSamples: 1','REST')\n",
    "\n",
    "m = re.match(r'Person(\\d+)Recording(\\d+)', 'Person5Recording4')\n",
    "person, rec = m.groups()\n",
    "df.insert(0,'Recording',int(rec))\n",
    "df.insert(0,'Person',   int(person))\n",
    "\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"Cleaned annotations, saved: {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_new = pd.read_csv('./csv_output/Person5Recording4.csv')\n",
    "df_new['annotation'] = df_new['annotation'].str.upper().str.strip()\n",
    "df_new = df_new[df_new['annotation'].str.contains('REST|MOVE|IMAGERY',na=False)].reset_index(drop=True)\n",
    "df_new['label'] = df_new['annotation'].apply(map_label)  # gjenbruk map_label\n",
    "\n",
    "# Hardkodete kanaler som i trening\n",
    "eeg_ch = eeg_channels\n",
    "\n",
    "# Drop non-numeric\n",
    "for ch in eeg_ch:\n",
    "    df_new[ch] = pd.to_numeric(df_new[ch], errors='coerce')\n",
    "df_new.dropna(subset=eeg_ch, inplace=True); df_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# RawArray + filtre\n",
    "sfreq = 500.\n",
    "info  = mne.create_info(ch_names=eeg_ch, sfreq=sfreq, ch_types='eeg')\n",
    "raw_new = mne.io.RawArray(df_new[eeg_ch].T.values, info)\n",
    "raw_new.notch_filter(50., fir_design='firwin', verbose=False)\n",
    "raw_new.filter(1., 40., fir_design='firwin', verbose=False)\n",
    "\n",
    "# Epoke 4s non-overlap + baseline\n",
    "data        = raw_new.get_data().T\n",
    "labels      = df_new['label'].values\n",
    "epoch_samps = int(4 * sfreq)\n",
    "\n",
    "X_new, y_new = [], []\n",
    "for st in range(0, len(data)-epoch_samps+1, epoch_samps):\n",
    "    seg      = data[st:st+epoch_samps]\n",
    "    baseline = seg[:int(0.5*sfreq)].mean(axis=0, keepdims=True)\n",
    "    seg_bc   = seg - baseline\n",
    "    X_new.append(seg_bc.T)\n",
    "    y_new.append(pd.Series(labels[st:st+epoch_samps]).mode()[0])\n",
    "\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)\n",
    "print(\"New epochs:\", X_new.shape)\n",
    "print(\"New label counts:\\n\", pd.Series(y_new).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23db098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_new_pred = pipe.predict(X_new)\n",
    "print(\"\\nHoldout Person5 accuracy:\", accuracy_score(y_new, y_new_pred))\n",
    "print(classification_report(\n",
    "    y_new, y_new_pred,\n",
    "    labels=['REST','MOVE','IMAGERY'],\n",
    "    target_names=['REST','MOVE','IMAGERY'],\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "cm = confusion_matrix(y_new, y_new_pred, labels=['REST','MOVE','IMAGERY'])\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks([0,1,2]); ax.set_xticklabels(['REST','MOVE','IMAGERY'])\n",
    "ax.set_yticks([0,1,2]); ax.set_yticklabels(['REST','MOVE','IMAGERY'])\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax.text(j, i, cm[i,j], ha='center', va='center',\n",
    "                color='white' if cm[i,j]>cm.max()/2 else 'black')\n",
    "ax.set_xlabel('Predikert'); ax.set_ylabel('Sann'); ax.set_title('Confusion Matrix Person5')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f2e75",
   "metadata": {},
   "source": [
    "## Deploy Standard Pipeline - Multiclass model Selfmade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Deploy Block: Multiclass Pipeline -----------------------------\n",
    "from joblib import dump\n",
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "# Katalog for artefakter\n",
    "ART_DIR = './saved_artifacts'\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "# 1) Lagre den trente multiclass-pipelinen\n",
    "dump(pipe, os.path.join(ART_DIR, 'multiclass_riemann_pipeline.joblib'))\n",
    "\n",
    "# 2) Lagre lista over EEG-kanaler\n",
    "with open(os.path.join(ART_DIR, 'eeg_channels.json'), 'w') as f:\n",
    "    json.dump(eeg_channels, f)\n",
    "\n",
    "# 3) Lagre preprosesserings-parametre\n",
    "preproc_meta = {\n",
    "    \"sfreq\":      int(sfreq),            # sampling rate, f.eks. 500\n",
    "    \"window_len\": int(4 * sfreq),        # antall samples per epoke, f.eks. 2000\n",
    "    \"step_len\":   int(4 * sfreq)         # steg-størrelse, tilsvarende vindustørrelse (ingen overlap)\n",
    "}\n",
    "with open(os.path.join(ART_DIR, 'preproc_meta.json'), 'w') as f:\n",
    "    json.dump(preproc_meta, f)\n",
    "\n",
    "# 4) Lagre rekkefølgen av klasser som modellen forventer\n",
    "#    pipe.classes_ inneholder ['REST', 'MOVE', 'IMAGERY']\n",
    "np.save(os.path.join(ART_DIR, 'label_classes.npy'), pipe.classes_)\n",
    "\n",
    "print(\"Deploy-complete: alle artefakter er lagret i:\", ART_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfb081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3ccd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5e70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ff050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d9d691f",
   "metadata": {},
   "source": [
    "# Standard Pipeline New Imported Dataset Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9014b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461d552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a51dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088fec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411edaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67733a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac0603c6",
   "metadata": {},
   "source": [
    "## Testing Standard Pipeline - Binary model NEW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc3e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29a755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ce5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd8f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfeec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b1e90ca",
   "metadata": {},
   "source": [
    "## Deploy Standard Pipeline - Binary model NEW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd45b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a275d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36707f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a1746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6141837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcaa5de3",
   "metadata": {},
   "source": [
    "# Standard Pipeline New Imported Dataset Multiclass Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a01b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8a239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e74ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf04602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cf799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e54a3a",
   "metadata": {},
   "source": [
    "## Testing Standard Pipeline - Multiclass model NEW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27f1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127ecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd0ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136a35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b53913e0",
   "metadata": {},
   "source": [
    "## Deploy Standard Pipeline - Multiclass model NEW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac2bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7af43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a9f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7bced0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG Master Env",
   "language": "python",
   "name": "eeg_master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
